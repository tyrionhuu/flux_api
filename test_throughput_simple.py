#!/usr/bin/env python3
"""
FLUX API ååé‡æµ‹è¯•å·¥å…· (ç®€åŒ–ç‰ˆ)
æµ‹è¯• FP4 æ¨¡å‹çš„å¹¶å‘å¤„ç†èƒ½åŠ›å’Œå“åº”æ—¶é—´
"""

import asyncio
import aiohttp
import time
import json
import statistics
import argparse
from typing import List, Dict, Any
from dataclasses import dataclass
from datetime import datetime
import threading


@dataclass
class TestResult:
    """æµ‹è¯•ç»“æœæ•°æ®ç±»"""
    request_id: str
    start_time: float
    end_time: float
    response_time: float
    status_code: int
    success: bool
    error_message: str = ""
    generation_time: float = 0.0
    vram_usage: str = ""


class SimpleFluxTester:
    """ç®€åŒ–çš„ FLUX API ååé‡æµ‹è¯•å™¨"""
    
    def __init__(self, base_url: str = "http://localhost:8000"):
        self.base_url = base_url
        self.results: List[TestResult] = []
        self.lock = threading.Lock()
        
        # æµ‹è¯•ç”¨çš„æç¤ºè¯
        self.test_prompts = [
            "ä¸€åªå¯çˆ±çš„å°çŒ«åœ¨èŠ±å›­é‡Œç©è€",
            "ç¾ä¸½çš„æ—¥è½é£æ™¯ç”»",
            "æœªæ¥ç§‘æŠ€åŸå¸‚å¤œæ™¯",
            "ä¼ ç»Ÿä¸­å›½å±±æ°´ç”»",
            "ç°ä»£æŠ½è±¡è‰ºæœ¯é£æ ¼",
            "ç«¥è¯æ•…äº‹ä¸­çš„åŸå ¡",
            "æµ·æ´‹æ·±å¤„çš„ç¥ç§˜ç”Ÿç‰©",
            "å¤ªç©ºä¸­çš„æ˜Ÿé™…é£èˆ¹",
            "æ£®æ—ä¸­çš„ç²¾çµä¸–ç•Œ",
            "å¤å¤é£æ ¼çš„è’¸æ±½æœ‹å…‹æœºæ¢°"
        ]
    
    async def test_single_request(self, session: aiohttp.ClientSession, prompt: str, 
                                request_id: str) -> TestResult:
        """æµ‹è¯•å•ä¸ªè¯·æ±‚"""
        start_time = time.time()
        
        payload = {
            "prompt": prompt,
            "num_inference_steps": 25,
            "guidance_scale": 3.5,
            "width": 512,
            "height": 512
        }
        
        try:
            async with session.post(
                f"{self.base_url}/generate",
                json=payload,
                timeout=aiohttp.ClientTimeout(total=300)  # 5åˆ†é’Ÿè¶…æ—¶
            ) as response:
                end_time = time.time()
                response_time = end_time - start_time
                
                if response.status == 200:
                    result_data = await response.json()
                    generation_time = float(result_data.get("generation_time", "0").replace("s", ""))
                    vram_usage = result_data.get("vram_usage_gb", "")
                    
                    return TestResult(
                        request_id=request_id,
                        start_time=start_time,
                        end_time=end_time,
                        response_time=response_time,
                        status_code=response.status,
                        success=True,
                        generation_time=generation_time,
                        vram_usage=vram_usage
                    )
                else:
                    error_text = await response.text()
                    return TestResult(
                        request_id=request_id,
                        start_time=start_time,
                        end_time=end_time,
                        response_time=response_time,
                        status_code=response.status,
                        success=False,
                        error_message=error_text
                    )
                    
        except Exception as e:
            end_time = time.time()
            return TestResult(
                request_id=request_id,
                start_time=start_time,
                end_time=end_time,
                response_time=end_time - start_time,
                status_code=0,
                success=False,
                error_message=str(e)
            )
    
    async def test_concurrent_requests(self, num_requests: int, max_concurrent: int = 3) -> Dict[str, Any]:
        """æµ‹è¯•å¹¶å‘è¯·æ±‚"""
        print(f"ğŸš€ å¼€å§‹å¹¶å‘æµ‹è¯•: {num_requests} ä¸ªè¯·æ±‚, æœ€å¤§å¹¶å‘æ•°: {max_concurrent}")
        
        # å‡†å¤‡è¯·æ±‚æ•°æ®
        requests_data = []
        for i in range(num_requests):
            prompt = self.test_prompts[i % len(self.test_prompts)]
            requests_data.append((prompt, f"req_{i:04d}"))
        
        # åˆ›å»ºä¿¡å·é‡é™åˆ¶å¹¶å‘æ•°
        semaphore = asyncio.Semaphore(max_concurrent)
        
        async def limited_request(session, prompt, request_id):
            async with semaphore:
                return await self.test_single_request(session, prompt, request_id)
        
        # æ‰§è¡Œå¹¶å‘æµ‹è¯•
        start_time = time.time()
        async with aiohttp.ClientSession() as session:
            tasks = [
                limited_request(session, prompt, request_id)
                for prompt, request_id in requests_data
            ]
            results = await asyncio.gather(*tasks, return_exceptions=True)
        
        end_time = time.time()
        total_time = end_time - start_time
        
        # å¤„ç†ç»“æœ
        with self.lock:
            self.results.extend([r for r in results if isinstance(r, TestResult)])
        
        return self.analyze_results(total_time, num_requests)
    

    
    async def test_model_status(self) -> Dict[str, Any]:
        """æµ‹è¯•æ¨¡å‹çŠ¶æ€å’Œç³»ç»Ÿä¿¡æ¯"""
        print("ğŸ” æ£€æŸ¥æ¨¡å‹çŠ¶æ€...")
        
        async with aiohttp.ClientSession() as session:
            # æ£€æŸ¥æ¨¡å‹çŠ¶æ€
            async with session.get(f"{self.base_url}/model-status") as response:
                if response.status == 200:
                    model_status = await response.json()
                else:
                    model_status = {"error": "æ— æ³•è·å–æ¨¡å‹çŠ¶æ€"}
            
            # æ£€æŸ¥GPUä¿¡æ¯
            async with session.get(f"{self.base_url}/gpu-info") as response:
                if response.status == 200:
                    gpu_info = await response.json()
                else:
                    gpu_info = {"error": "æ— æ³•è·å–GPUä¿¡æ¯"}
            
            # æ£€æŸ¥é˜Ÿåˆ—ç»Ÿè®¡
            async with session.get(f"{self.base_url}/queue-stats") as response:
                if response.status == 200:
                    queue_stats = await response.json()
                else:
                    queue_stats = {"error": "æ— æ³•è·å–é˜Ÿåˆ—ç»Ÿè®¡"}
            
            return {
                "model_status": model_status,
                "gpu_info": gpu_info,
                "queue_stats": queue_stats,
                "timestamp": datetime.now().isoformat()
            }
    
    def analyze_results(self, total_time: float, num_requests: int) -> Dict[str, Any]:
        """åˆ†ææµ‹è¯•ç»“æœ"""
        successful_results = [r for r in self.results if r.success]
        failed_results = [r for r in self.results if not r.success]
        
        if not successful_results:
            return {
                "total_requests": num_requests,
                "successful_requests": 0,
                "failed_requests": len(failed_results),
                "success_rate": 0.0,
                "total_time": total_time,
                "throughput": 0.0,
                "error": "æ²¡æœ‰æˆåŠŸçš„è¯·æ±‚"
            }
        
        response_times = [r.response_time for r in successful_results]
        generation_times = [r.generation_time for r in successful_results if r.generation_time > 0]
        
        analysis = {
            "total_requests": num_requests,
            "successful_requests": len(successful_results),
            "failed_requests": len(failed_results),
            "success_rate": len(successful_results) / num_requests * 100,
            "total_time": total_time,
            "throughput": len(successful_results) / total_time,  # è¯·æ±‚/ç§’
            "avg_response_time": statistics.mean(response_times),
            "median_response_time": statistics.median(response_times),
            "min_response_time": min(response_times),
            "max_response_time": max(response_times),
            "response_time_std": statistics.stdev(response_times) if len(response_times) > 1 else 0,
            "avg_generation_time": statistics.mean(generation_times) if generation_times else 0,
            "median_generation_time": statistics.median(generation_times) if generation_times else 0,
            "errors": [r.error_message for r in failed_results] if failed_results else []
        }
        
        return analysis
    
    def generate_report(self, test_name: str, results: Dict[str, Any]):
        """ç”Ÿæˆæµ‹è¯•æŠ¥å‘Š"""
        print(f"\n{'='*60}")
        print(f"ğŸ“Š {test_name} æµ‹è¯•æŠ¥å‘Š")
        print(f"{'='*60}")
        
        print(f"ğŸ“ˆ æ€»ä½“ç»Ÿè®¡:")
        print(f"   æ€»è¯·æ±‚æ•°: {results['total_requests']}")
        print(f"   æˆåŠŸè¯·æ±‚: {results['successful_requests']}")
        print(f"   å¤±è´¥è¯·æ±‚: {results['failed_requests']}")
        print(f"   æˆåŠŸç‡: {results['success_rate']:.2f}%")
        print(f"   æ€»è€—æ—¶: {results['total_time']:.2f}ç§’")
        print(f"   ååé‡: {results['throughput']:.2f} è¯·æ±‚/ç§’")
        
        print(f"\nâ±ï¸  å“åº”æ—¶é—´:")
        print(f"   å¹³å‡å“åº”æ—¶é—´: {results['avg_response_time']:.2f}ç§’")
        print(f"   ä¸­ä½æ•°å“åº”æ—¶é—´: {results['median_response_time']:.2f}ç§’")
        print(f"   æœ€å°å“åº”æ—¶é—´: {results['min_response_time']:.2f}ç§’")
        print(f"   æœ€å¤§å“åº”æ—¶é—´: {results['max_response_time']:.2f}ç§’")
        print(f"   å“åº”æ—¶é—´æ ‡å‡†å·®: {results['response_time_std']:.2f}ç§’")
        
        if results.get('avg_generation_time', 0) > 0:
            print(f"\nğŸ¨ ç”Ÿæˆæ—¶é—´:")
            print(f"   å¹³å‡ç”Ÿæˆæ—¶é—´: {results['avg_generation_time']:.2f}ç§’")
            print(f"   ä¸­ä½æ•°ç”Ÿæˆæ—¶é—´: {results['median_generation_time']:.2f}ç§’")
        
        if results.get('errors'):
            print(f"\nâŒ é”™è¯¯ä¿¡æ¯:")
            for error in results['errors'][:5]:  # åªæ˜¾ç¤ºå‰5ä¸ªé”™è¯¯
                print(f"   - {error}")
            if len(results['errors']) > 5:
                print(f"   ... è¿˜æœ‰ {len(results['errors']) - 5} ä¸ªé”™è¯¯")
        
        print(f"{'='*60}\n")
    
    def print_summary_table(self):
        """æ‰“å°æ±‡æ€»è¡¨æ ¼"""
        if not self.results:
            print("âŒ æ²¡æœ‰æµ‹è¯•ç»“æœ")
            return
        
        successful_results = [r for r in self.results if r.success]
        if not successful_results:
            print("âŒ æ²¡æœ‰æˆåŠŸçš„æµ‹è¯•ç»“æœ")
            return
        
        print(f"\nğŸ“‹ æµ‹è¯•ç»“æœæ±‡æ€»è¡¨")
        print(f"{'='*80}")
        print(f"{'è¯·æ±‚ID':<10} {'çŠ¶æ€':<8} {'å“åº”æ—¶é—´(s)':<12} {'ç”Ÿæˆæ—¶é—´(s)':<12} {'VRAMä½¿ç”¨':<12}")
        print(f"{'='*80}")
        
        for result in successful_results[:20]:  # åªæ˜¾ç¤ºå‰20ä¸ªç»“æœ
            status = "âœ…" if result.success else "âŒ"
            response_time = f"{result.response_time:.2f}"
            generation_time = f"{result.generation_time:.2f}" if result.generation_time > 0 else "N/A"
            vram_usage = result.vram_usage if result.vram_usage else "N/A"
            
            print(f"{result.request_id:<10} {status:<8} {response_time:<12} {generation_time:<12} {vram_usage:<12}")
        
        if len(successful_results) > 20:
            print(f"... è¿˜æœ‰ {len(successful_results) - 20} ä¸ªç»“æœ")
        
        print(f"{'='*80}")


async def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description="FLUX API ååé‡æµ‹è¯•å·¥å…· (ç®€åŒ–ç‰ˆ)")
    parser.add_argument("--url", default="http://localhost:8000", help="API åŸºç¡€URL")
    parser.add_argument("--requests", type=int, default=10, help="æµ‹è¯•è¯·æ±‚æ•°é‡")
    parser.add_argument("--concurrent", type=int, default=3, help="æœ€å¤§å¹¶å‘æ•°")
    parser.add_argument("--test-type", choices=["concurrent"], 
                       default="concurrent", help="æµ‹è¯•ç±»å‹")
    parser.add_argument("--save", action="store_true", help="ä¿å­˜è¯¦ç»†ç»“æœåˆ°JSONæ–‡ä»¶")
    
    args = parser.parse_args()
    
    print("ğŸš€ FLUX API ååé‡æµ‹è¯•å·¥å…· (ç®€åŒ–ç‰ˆ)")
    print(f"ğŸ“ API URL: {args.url}")
    print(f"ğŸ“Š æµ‹è¯•é…ç½®: {args.requests} è¯·æ±‚, {args.concurrent} å¹¶å‘")
    print(f"ğŸ¯ æµ‹è¯•ç±»å‹: {args.test_type}")
    
    tester = SimpleFluxTester(args.url)
    
    # æ£€æŸ¥æ¨¡å‹çŠ¶æ€
    print("\nğŸ” æ£€æŸ¥ç³»ç»ŸçŠ¶æ€...")
    status = await tester.test_model_status()
    print(f"æ¨¡å‹çŠ¶æ€: {status['model_status'].get('model_loaded', 'Unknown')}")
    print(f"GPU ä¿¡æ¯: {status['gpu_info']}")
    print(f"é˜Ÿåˆ—ç»Ÿè®¡: {status['queue_stats']}")
    
    # æ‰§è¡Œæµ‹è¯•
    print(f"\nğŸ”„ å¼€å§‹å¹¶å‘æµ‹è¯•...")
    concurrent_results = await tester.test_concurrent_requests(
        args.requests, args.concurrent
    )
    tester.generate_report("å¹¶å‘è¯·æ±‚", concurrent_results)
    
    # æ‰“å°æ±‡æ€»è¡¨æ ¼
    tester.print_summary_table()
    
    # ä¿å­˜è¯¦ç»†ç»“æœ
    if args.save:
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        results_file = f"throughput_test_results_{timestamp}.json"
        
        detailed_results = {
            "test_config": {
                "url": args.url,
                "requests": args.requests,
                "concurrent": args.concurrent,
                "test_type": args.test_type
            },
            "system_status": status,
            "test_results": [
                {
                    "request_id": r.request_id,
                    "start_time": r.start_time,
                    "end_time": r.end_time,
                    "response_time": r.response_time,
                    "status_code": r.status_code,
                    "success": r.success,
                    "error_message": r.error_message,
                    "generation_time": r.generation_time,
                    "vram_usage": r.vram_usage
                }
                for r in tester.results
            ]
        }
        
        with open(results_file, 'w', encoding='utf-8') as f:
            json.dump(detailed_results, f, indent=2, ensure_ascii=False)
        
        print(f"ğŸ“„ è¯¦ç»†ç»“æœå·²ä¿å­˜åˆ°: {results_file}")


if __name__ == "__main__":
    asyncio.run(main()) 